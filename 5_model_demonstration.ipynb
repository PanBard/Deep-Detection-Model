{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540669d-f03a-4e39-8445-9ffdfec9b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a36f0-121f-4889-9ef5-ab0c5f33da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'jbl.keras'\n",
    "model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee67c9-edb3-41ba-a281-f2983564f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c788b-771a-408b-92f4-9ef61eb8a052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _ , frame = cap.read()\n",
    "    frame = frame[50:500, 50:500,:]\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(rgb, (120,120))\n",
    "    \n",
    "    yhat = model.predict(np.expand_dims(resized/255,0))\n",
    "    sample_coords = yhat[1][0]\n",
    "    print(\"yhat[0] = \", yhat)\n",
    "    if yhat[0] > 0.1: \n",
    "        # Controls the main rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "        # Controls the label rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,0,0), -1)\n",
    "        \n",
    "        # Controls the text rendered\n",
    "        cv2.putText(frame, model_name, tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                               [0,-5])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Webcam', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f8659-5b03-4eee-823c-5a074779d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_image(x): \n",
    "#     byte_img = tf.io.read_file(x)\n",
    "#     img = tf.io.decode_jpeg(byte_img)\n",
    "#     return img\n",
    "    \n",
    "# new_images = tf.data.Dataset.list_files('old\\\\data\\\\train\\\\images\\\\*.jpg', shuffle=False)\n",
    "# new_images = new_images.map(load_image)\n",
    "# new_images = new_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "# new_images = new_images.map(lambda x: x/255)\n",
    "\n",
    "# test = tf.data.Dataset.zip((new_images, ()))\n",
    "# test = test.shuffle(1300)\n",
    "# test = test.batch(8)\n",
    "# test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1232a-1e57-40a1-9163-45aaea764d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test.as_numpy_iterator()\n",
    "# test_sample = test_data.next()\n",
    "# # print(test_sample)\n",
    "# yhat = model.predict(test_sample)\n",
    "# print(\"yhat[0] = \", yhat)\n",
    "# fig, ax = plt.subplots(ncols=8, figsize=(20,20))\n",
    "# for idx in range(8): \n",
    "#     sample_image = test_sample[0][idx].copy()\n",
    "#     sample_coords = yhat[1][idx]\n",
    "    \n",
    "#     if yhat[0][idx] > 0.9:\n",
    "#         cv2.rectangle(sample_image, \n",
    "#                       tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "#                       tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "#                             (255,0,0), 2)\n",
    "    \n",
    "#     ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad94ff-12cb-4c73-b264-fa7ec12e3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img\n",
    "    \n",
    "new_images = tf.data.Dataset.list_files('data\\\\augmented_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "new_images = new_images.map(load_image)\n",
    "new_images = new_images.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "new_images = new_images.map(lambda x: x/255)\n",
    "\n",
    "test = tf.data.Dataset.zip((new_images, ()))\n",
    "test = test.shuffle(1300)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)\n",
    "\n",
    "\n",
    "test_data = test.as_numpy_iterator()\n",
    "test_sample = test_data.next()\n",
    "yhat = model.predict(test_sample[0])\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx in range(4): \n",
    "    sample_image = test_sample[0][idx].copy()\n",
    "    sample_coords = yhat[1][idx]\n",
    "    \n",
    "    if yhat[0][idx] > 0.9:\n",
    "        cv2.rectangle(sample_image, \n",
    "                      tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [120,120]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "    \n",
    "    ax[idx].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06ec6d-6f0b-4dcf-83a6-4a2d6b86529f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
